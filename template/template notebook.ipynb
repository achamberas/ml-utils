{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Template ML Notebook\n",
        "\n",
        "This notebook provides a template on how to pre-process data, train and evaluate models. Goal is to standardize model development process in order for it to be more scalable & robust. \n",
        "\n",
        "## Set up & prerequisite\n",
        "* Create and copy a [Github Personal Access Token](https://docs.github.com/en/enterprise-server@3.8/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens#creating-a-personal-access-token) and use it to set the `GITHUB_PERSONAL_ACCESS_TOKEN` variable\n",
        "* If using Google Colab, create secrets for the following variables:\n",
        "    * GITHUB_PERSONAL_ACCESS_TOKEN\n",
        "    * CLIENT_SECRET\n",
        "* Ensure that google cloud account is set up (needed in order to store models & perform queries)\n",
        "* Ensure all of the libraries are installed by running `!pip install git+https://{GITHUB_PERSONAL_ACCESS_TOKEN}@github.com/autocase/joulesAI.git@{LIBS_VERSION}`\n",
        "    **RECOMMENDED**: If running locally, create and use a virtual environment to prevent dependency conflicts:\n",
        "    ```\n",
        "    python -m venv <venv>\n",
        "    source <venv>/bin/activate\n",
        "    ``` \n",
        "    Select the virtual environment as the kernal for the template notebook.\n",
        "* To reinstall the library, run:\n",
        "    ```\n",
        "    pip install pef\n",
        "    pef libs -y\n",
        "    ```\n",
        "\n",
        "## High Level Steps From The Template\n",
        "\n",
        "1. Import required libraries & set appropriate environment variables\n",
        "2. Get training data\n",
        "3. Preform feature engineering \n",
        "4. Balance the dataset\n",
        "5. Train & Evaluate a model\n",
        "6. Perform grid search to pick best params\n",
        "7. Retrain the model with best params\n",
        "8. Perform error analysis\n",
        "\n",
        "Below are more in depth explanation of some of the steps.\n",
        "\n",
        "## Feature Engineering\n",
        "\n",
        "There are a few feature eningeering steps that happen:\n",
        "* Dates get additional features like `Month`, `year`, `Is_year_end` etc.\n",
        "* Numerical features get standardized\n",
        "* Categorical features are one hot encoded\n",
        "* Building specific features like CFA, TWR etc. get added\n",
        "\n",
        "\n",
        "## Balancing a dataset\n",
        "\n",
        "If the target variable is unbalanced, the notebook performs downsampling of the target variable in order to increase model performance & increase robustness.\n",
        "\n",
        "## Training & Evaluating Models\n",
        "\n",
        "Notebook offers a standardized way to train a model. By default it trains a random forrest regressor with a set of default params. \n",
        "\n",
        "Model evaluation is also standardized and by default evaluates model against a set of default metrics (for regression those would RMSE etc.)\n",
        "\n",
        "## Grid Search\n",
        "\n",
        "In order to find best params for the model grid search is also performed in the notebook. There are set of default params defined, but those can be customized as shown in the notebook example.\n",
        "\n",
        "## Notebook Configuration\n",
        "\n",
        "In case there is a need for a different model to be ran, different kind of transformation to be applied and grid search params to be updpated all of the configuration is stored in `libs/vars.py`\n",
        "\n",
        "`CONFIG` variable sets a few basic paramaters up and can be updated in case a different type of model needs to be trained or a target variable name changes.\n",
        "\n",
        "`DEFAULT_GRID_SEARCH` is a set of default params for grid search. Can be change in case defaults need to be updated.\n",
        "\n",
        "`TRANSFORM_FUNCTIONS` is a set of default functions that transform a given variable. Can be updated in case there additional transformation functions that need to be performed.\n",
        "\n",
        "`DEFAULT_RandomForestRegressor_HP` is a set of default params for a random forrest regressor. Can be update in case different defaults have to be applied."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LO4DTtElVPAR"
      },
      "source": [
        "# Libaries & Environment Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Setting environment variables that are required to run this template. Update in case params change\n",
        "'''\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"sa_key_file.json\"\n",
        "os.environ[\"GOOGLE_PROJECT\"] = \"autocase-201317\"\n",
        "os.environ[\"BQ_DATASET\"] = \"eplus_simulations\"\n",
        "os.environ[\"MLFLOW_TRACKING_URL\"] = \"https://mlflow.autocase.dev\"\n",
        "\n",
        "# GITHUB_PERSONAL_ACCESS_TOKEN = 'ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'\n",
        "# CLIENT_SECRET = 'xxxxxxxxxxxxxxxxxxxxx'\n",
        "\n",
        "GITHUB_PERSONAL_ACCESS_TOKEN = userdata.get('GITHUB_PERSONAL_ACCESS_TOKEN')\n",
        "CLIENT_SECRET = userdata.get('CLIENT_SECRET')\n",
        "\n",
        "LIBS_VERSION = 'ds-libs-and-template'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSGuy8D5TVVq",
        "outputId": "8724c050-ba1c-4980-d094-48744405a6a1"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Install packages that are required to run this template.\n",
        "'''\n",
        "\n",
        "!pip install git+https://{GITHUB_PERSONAL_ACCESS_TOKEN}@github.com/autocase/joulesAI.git@{LIBS_VERSION}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Importing all of the internal libraries from libs folder\n",
        "'''\n",
        "\n",
        "import libs.connect \n",
        "import libs.preprocess \n",
        "import libs.train \n",
        "import libs.predict \n",
        "import libs.vars \n",
        "import libs.mlflow_token\n",
        "\n",
        "from libs.connect import * # containts functions to connect to google cloud & get simulation data/jobs\n",
        "from libs.preprocess import * # contains functions for data preprocessing (creating additional features, combining datasets etc.)\n",
        "from libs.train import * # contains functions for training & evaluating models\n",
        "from libs.predict import * # contains functions for running inference on models\n",
        "from libs.vars import * # contains common paramater configurations for grid search, random forest etc.\n",
        "from libs.mlflow_token import * # contains library to fetch MLFLOW Auth token and save to env var.\n",
        "\n",
        "config = CONFIG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get token for ML Flow server\n",
        "# Follow link generated by this cell, and manually authenticate to MLFlow\n",
        "# Token will be saved to env\n",
        "\n",
        "tracking_url = os.getenv('MLFLOW_TRACKING_URL')\n",
        "client_secret = CLIENT_SECRET\n",
        "\n",
        "setup_mlflow_environment(tracking_url, client_secret)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6LgclHMWu0Z"
      },
      "source": [
        "# Baseline Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### List Simulation Jobs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Get all of the current simulation jobs from googles task manager\n",
        "'''\n",
        "\n",
        "get_simulation_jobs()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUARbl6JhVdJ",
        "outputId": "c046c49f-9754-43d4-d165-7223f8533399"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Configure target variable, training data id and climate zones, get the simulation data and plot the target variable\n",
        "'''\n",
        "\n",
        "# configuring variables\n",
        "config['target'] = \"total_eui_elec_gj_m2\"\n",
        "config['training_data_simid'] = ['20240124-150716-L1H9L', '20240122-175354-ZTPMH']\n",
        "config['climate_zones'] = [\"5A\", \"5B\", \"5C\", \"6A\", \"6B\"]\n",
        "\n",
        "# getting simulation data\n",
        "df = get_simulation_data(config['training_data_simid'], config['target'], config['climate_zones'])\n",
        "\n",
        "# plotting distribution of the target variable\n",
        "df[config['target']].hist(bins=30, rwidth=0.75)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Add Combined Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Create new features to add to the training dataset (CFA, TWWR etc.) and plot the histogram of the target variable\n",
        "'''\n",
        "\n",
        "# create new features\n",
        "df = getCombinedFeatures(df, toEnergyUsage = True, target=config['target'])\n",
        "\n",
        "# plotting distribution of the target variable\n",
        "df[config['target']].hist(bins=30, rwidth=0.75)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Select Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "select which columns to exclude from the feature set\n",
        "'''\n",
        "\n",
        "# select columns to remove\n",
        "config['drop_cols'] = [\"ESA\", \"AR\", \"HD\", \"ahu_burner_efficiency\", \"supply_air_temp_heating\", \"temp_setpoint_heating_occupied\", \"temp_setpoint_heating_setback\", \"total_eui_ng_gj_m2\", \"total_eui_elec_gj_m2\", \"total_eui_elec_gj_m2_ln\", \"id\", \"job_id\", \"sample_id\"]\n",
        "\n",
        "# select a list of features (without the removed columns)\n",
        "cols = df.columns\n",
        "features = list(set(cols) - set(config['drop_cols']))\n",
        "features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split Datasset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "i_aDkgImh5lu",
        "outputId": "7cc6eeea-57bb-439d-92b3-cc399e8ce823"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Splits dataset into training and test sets\n",
        "'''\n",
        "\n",
        "config['random_seed'] = 100 # set a random seed so the data splits are reproducable\n",
        "X_train, X_test, y_train, y_test, feature_info = split_dataset(df, features, config['target'], config['random_seed']) # split data into training and testing\n",
        "feature_info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Handle NULLs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = X_train.fillna(0)\n",
        "X_test = X_test.fillna(0)\n",
        "y_train = y_train.fillna(0)\n",
        "y_test = y_test.fillna(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train the selected model\n",
        "\n",
        "config['model']['algorithm'] = 'RandomForestRegressor' # specify a model \n",
        "model = train_model(config['model']['algorithm'], X_train, y_train) # train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Evaluate a model\n",
        "'''\n",
        "\n",
        "config['transformation'] = '' # specify transformation if needed\n",
        "model_metrics, importances_df, y_pred = evaluate(model, X_test, y_test, transform_fx=config['transformation'], title=config['experiment_name']) # evaluate the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Perform grid search to find a model with best param\n",
        "'''\n",
        "\n",
        "grid_search_params = {\n",
        "    \"param_distributions\": {\n",
        "        \"n_estimators\": [10,100],   # num of trees in forest\n",
        "        \"max_features\": ['sqrt'],   # num features @ split\n",
        "        \"max_depth\": [100],         # Max num of levels in tree\n",
        "        \"min_samples_split\": [2],   # Min num samples to split node\n",
        "        \"min_samples_leaf\": [1],    # Min num samples required @ leaf node\n",
        "        \"bootstrap\": [True, False]  # sample selection method\n",
        "    },\n",
        "    \"n_iter\": 10, # number of iterations\n",
        "    \"cv\": 2, # number of folds\n",
        "    \"verbose\": 0, \n",
        "    \"random_state\": 42, # setting the seed\n",
        "    \"n_jobs\": -1 # number of jobs to run in parallel. -1 means using all processors.\n",
        "}\n",
        "\n",
        "best_hyperparameters = grid_search(config['model']['algorithm'], X_train, y_train, grid_search_params) # perform grid search\n",
        "\n",
        "best_hyperparameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Retrain & evaluate model with best hyperparameters\n",
        "'''\n",
        "\n",
        "model = train_model(config['model']['algorithm'], X_train, y_train, best_hyperparameters) # retrain model with best hyperparameters\n",
        "model_metrics, importances_df, y_pred = evaluate(model, X_test, y_test, transform_fx=config['transformation'], title=config['experiment_name']) # evaluate model with best hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Error Analysis\n",
        "\n",
        "Sample Plan\n",
        "https://docs.google.com/spreadsheets/d/120glSDNi1COUMeu-B9KnbfzSkzKM7syY/edit?usp=sharing&ouid=103559666706832096026&rtpof=true&sd=true\n",
        "\n",
        "Error Analysis\n",
        "https://docs.google.com/spreadsheets/d/18IqPK4H9RoaX-aohsHqFegzqfQcKOjWkRWE_L_IG30I/edit?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Perform error analysis\n",
        "'''\n",
        "\n",
        "config['error_analysis_simid'] = ['20240119-221157-QW06O']\n",
        "\n",
        "error_analysis(config['error_analysis_simid'], config['target'], model, feature_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save Expirement to ML Flow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Save the selected model to ML Flow\n",
        "'''\n",
        "\n",
        "save_experiment(model, feature_info, model_metrics, config)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNLeKJ+ysTKUWhlhqUIjx6w",
      "collapsed_sections": [
        "LO4DTtElVPAR",
        "pUnKx1ebhV9A"
      ],
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
